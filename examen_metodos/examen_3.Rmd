---
title: "Parte 3: Recomendación"
output: html_document
---

# Instrucciones

```{r, echo=F, error=F, warning=F, message=F}
library(dplyr)
library(Matrix)
options(digits=4)
library(ggplot2)
library(stringr)
library(reshape2)
library(tidyr)
```

https://movielens.org

Utilizaremos datos de movielens:

These files contain 1,000,209 anonymous ratings of approximately 3,900 movies 
made by 6,040 MovieLens users who joined MovieLens in 2000.


```{r}
rat <- read.table('ml-1m/ratings.dat',header=F, sep=":")
rat$V2 <- NULL
rat$V4 <- NULL
rat$V6 <- NULL
head(rat)
names(rat) <- c('user_id','movie_id','rating')
# rat.2 <- rat %>% group_by(user_id) %>%
#   mutate(media.usu = mean(rating)) %>%
#   group_by(movie_id) %>%
#   mutate(media.movie = mean(rating)) %>%
#   ungroup() %>%
#   mutate(media = mean(rating)) %>%
#   mutate(rating.adj = rating - (media.movie + media.usu - media))
# 
# i <- rat.2$user_id
# j <- rat.2$movie_id
# x <- rat.2$rating.adj
# X <- sparseMatrix(i=i,j=j,x=x)
```


```{r}
con <- file("ml-1m/movies.dat", "r", blocking = FALSE)
lineas <- readLines(con) # empty
close(con)
lista.movies <- list()
salida <- lapply(lineas, function(linea){
  sp <- strsplit(linea, '::', fixed=T)[[1]]
  data_frame(movie_id = sp[1], movie_nom = sp[2], tipo = sp[3])
})
movies.df <- rbind_all(salida)
movies.df$movie_id <- as.integer(movies.df$movie_id)
```

1. Construye una muestra de entrenamiento y una de validación
2. Ajusta y evalúa el modelo base.
3. Utiliza descenso estocástico o descomposición en valores singulares para encontrar factores latentes (ajustados a los residuales del modelo base). 
4. Explica cómo hacer predicciones a partir del modelo (predicción de la calificación 1-5). ¿Qué películas recomendarías para el usuario usuario 4000 y el usuario 6000, y usuario 1333? (que no haya visto!)
5. Evalúa el modelo de factores latentes que ajustaste usando la muestra de validación.

Nota: puedes intentar usar el código de clase para descenso en gradiente. También puedes usar este código simple que hace descomposición en valores singulares:

```{r, eval=F}
library("irlba")
out <- irlba(X, nu=50, nv=50) # 50 factores latentes con svd, 
factores.peliculas <- data.frame(out$v%*%diag(sqrt(out$d)), movie_id=1:nrow(out$v)) %>% 
  left_join(movies.df) %>%
  arrange(desc(X2))
factores.personas <- data.frame(out$u%*%diag(sqrt(out$d)), user_id=1:nrow(out$u))
```

# Muestra de validacion y de entrenamiento

```{r}
#Cuantas pelis
pelis <- length(unique(rat$movie_id))
#Cuantos usuarios
usuarios <- length(unique(rat$user_id))

rat <-rat[,-4]
# Usamos una muestra del 30% de peliculas, 30% de usuarios para validacion
set.seed(28882)
valida_usuarios <- sample(unique(rat$user_id), 0.1*usuarios) 
valida_pelis <- sample(unique(rat$movie_id), 0.1*pelis)


dat.2 <- rat %>%
  dplyr::mutate(valida_usu= user_id %in% valida_usuarios) %>%
  dplyr::mutate(valida_peli = movie_id %in% valida_pelis)

## reescribimos ids:
dat.2$movie_id_2 <- as.numeric(factor(dat.2$movie_id))

### juntamos nombres
dat.2 <- dat.2 %>% left_join(movies.df)

dat.entrena <- dplyr::filter(dat.2, !valida_usu | !valida_peli)
dat.valida <- dplyr::filter(dat.2, valida_usu & valida_peli)
nrow(dat.entrena) + nrow(dat.valida)
nrow(dat.2)
```

# Modelo base

Si $x_{ij}$ es el gusto del usuario $i$ por la película $j$, entonces nuestra predicción
es
$$\hat{x}_{uj} = \hat{b}_j +  (\hat{a}_i-\hat{\mu} ) $$

donde $a_i$ indica un nivel general de calificaciones del usuario $i$, y $b_j$ es el nivel general de gusto por la película. Usualmente ponemos:


1. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Promedio de calificaciones de usuario $i$ 
$$\hat{a}_i =\frac{1}{M_i}\sum_{t} x_{i,t} $$
3. Promedio de calificaciones de la película $j$ 
$$\hat{b}_j =\frac{1}{N_j}\sum_{s} x_{s,j}$$

También podemos escribir, en términos de desviaciones:

$$\hat{x}_{ij} = \hat{\mu}  +  \hat{c}_i +  \hat{d}_j $$
donde

. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Desviación de las calificaciones de usuario $i$ respecto a la media general
$$\hat{c}_i =\frac{1}{M_i}\sum_{t} x_{it} - \hat{\mu} $$
3. Desviación  de la película $j$ respecto a la media general
$$\hat{b_j} =\frac{1}{N_j}\sum_{s} x_{sj}- \hat{\mu}$$


Una vez que observamos una calificación $x_{ij}$, el residual del modelo de referencia es
$$r_{ij} = x_{ij} - \hat{x_{ij}}$$

```{r}

medias.usuario.e <- dat.entrena %>% group_by(user_id) %>% dplyr::summarise(media_usu = mean(rating), num_calif_usu = length(rating))
medias.peliculas.e <- dat.entrena %>% group_by(movie_id) %>% summarise(media_peli = mean(rating), num_calif_peli = length(rating))
media.gral.e <- mean(dat.entrena$rating)
dat.valida.2 <- dat.valida %>%
  left_join(medias.usuario.e) %>%
  left_join(medias.peliculas.e) %>%
  mutate(media.gral = media.gral.e) %>%
  mutate(prediccion = media_usu - media.gral + media_peli)

# sin prediccion, inputamos con la media general
dat.valida.2$prediccion[is.na(dat.valida.2$prediccion)] <- media.gral.e

sqrt(mean((dat.valida.2$prediccion - dat.valida.2$rating)^2))
```

Revisemos un poco mas el error de validacion. Veamos cual es el efecto de las peliculas que tienen pocas calificaciones. Se ve que tenemos la dificultad del ruido para centrar las calificaciones de usuarios o películas cuando hay pocas calificaciones.

```{r}
medias.peliculas <- dat.2 %>% group_by(movie_id) %>% summarise(media_peli = mean(rating), num_calif_peli = length(rating))
media.gral <- mean(dat.2$rating)
medias.p.2 <- left_join(medias.peliculas, movies.df)
arrange(medias.p.2, desc(media_peli)) %>% head

ggplot(medias.p.2, aes(x=num_calif_peli, y=media_peli)) + geom_point()
```

Podemos regularizar tomando

$$
\hat{x_{ij}} = \hat{\mu} + \frac{n_i}{\lambda+n_i} \hat{a_i} + \frac{m_j}{\lambda+m_j}\hat{b_j} 
$$

```{r}
error.valida <- sapply(c(0.001,0.01,0.1,1,5,10,20,40,60,80,100,200), 
                function(lambda){

                  dat.valida.2 <- dat.valida %>%
                    left_join(medias.usuario.e, by='user_id') %>%
                    left_join(medias.peliculas.e, by='movie_id') %>%
                    mutate(media.gral = media.gral.e) %>%
                    mutate(prediccion = media.gral + (num_calif_usu/(num_calif_usu+lambda))*(media_usu - media.gral) +
             (num_calif_peli/(num_calif_peli+lambda))*(media_peli-media.gral))
                 dat.valida.2$prediccion[is.na(dat.valida.2$prediccion)] <- media.gral.e
  
                 sqrt(mean((dat.valida.2$prediccion - dat.valida.2$rating)^2))
})

plot(error.valida)
```

El minimio del error de validacion se obtiene en `r min(error.valida)`. Sin embargo, este no dista mucho del maximo `r max(error.valida)`.

```{r,eval=F, echo=F}
lambda <- 40
dat.valida.2 <- dat.valida %>%
                    left_join(medias.usuario.e, by='user_id') %>%
                    left_join(medias.peliculas.e, by='movie_id') %>%
                    mutate(media.gral = media.gral.e) %>%
                    mutate(prediccion = media.gral + (num_calif_usu/(num_calif_usu+lambda))*(media_usu - media.gral) +
             (num_calif_peli/(num_calif_peli+lambda))*(media_peli-media.gral))
                 dat.valida.2$prediccion[is.na(dat.valida.2$prediccion)] <- media.gral.e
  
                 sqrt(mean((dat.valida.2$prediccion - dat.valida.2$rating)^2))

dat.entrena.2 <- dat.entrena %>%
                    left_join(medias.usuario.e, by='user_id') %>%
                    left_join(medias.peliculas.e, by='movie_id') %>%
                    mutate(media.gral = media.gral.e) %>%
                    mutate(prediccion = media.gral + (num_calif_usu/(num_calif_usu+lambda))*(media_usu - media.gral) +
             (num_calif_peli/(num_calif_peli+lambda))*(media_peli-media.gral))
                 dat.entrena.2$prediccion[is.na(dat.entrena.2$prediccion)] <- media.gral.e
  
                 sqrt(mean((dat.entrena.2$prediccion - dat.entrena.2$rating)^2))
```


# Descenso estocastico

Generamos matrices ralas de entrenamiento y validacion.

```{r}
dat.entrena.2 <- dat.entrena %>%
    left_join(medias.usuario.e) %>%
    left_join(medias.peliculas.e) %>%
    mutate(prediccion = media_usu - media.gral.e + media_peli) %>%
    mutate(rating.adj = rating - prediccion) 

dat.valida.2 <- dat.valida %>%
    left_join(medias.usuario.e) %>%
    left_join(medias.peliculas.e) %>%
    mutate(prediccion = media_usu - media.gral.e + media_peli) %>%
    mutate(rating.adj = rating - prediccion) 

i <- dat.entrena.2$user_id
j <- dat.entrena.2$movie_id_2
x <- dat.entrena.2$rating.adj
X <- sparseMatrix(i=i,j=j,x=x)


i.v <- dat.valida.2$user_id
j.v <- dat.valida.2$movie_id_2
x.v <- dat.valida.2$rating.adj
X.v <- sparseMatrix(i=i,j=j,x=x)
```

```{r}
library(Rcpp)
Rcpp::sourceCpp('src/netflix_gradiente.cpp') 
Rcpp::sourceCpp('src/calc_error_bias.cpp')
```

Primero, se deben inicializar los parametros

```{r}
#inicializar parámetros
set.seed(2805)
P <- matrix(rnorm(5*dim(X)[1],0,0.01), ncol=5, nrow=dim(X)[1]) # tantos renglones y columnas como personas
Q <- matrix(rnorm(5*dim(X)[2],0,0.01), ncol=5, nrow=dim(X)[2]) # tantos renglones y columnas como peliculas
a <- rep(0, dim(X)[1])
b <- rep(0, dim(X)[2])

## raíz de ecm:
sqrt(calc_error(i,j,x, P, Q, a,b))
sqrt(calc_error(i.v,j.v,x.v, P, Q,a,b))



for(k in 1:10){
  print(k)
  out <- netflix_gradiente(i, j, x, P, Q, a, b, 0.004, 0.01)
  P <- out[[1]]
  Q <- out[[2]]
  a <- out[[3]]
  b <- out[[4]]
  print(sqrt(calc_error(i, j, x, P, Q, a, b)))
  print(sqrt(calc_error(i.v, j.v, x.v, P, Q, a, b)))
}

num_pelis <- dat.entrena.2 %>% group_by(movie_id) %>% summarise(num = length(rating))

### Hay una bronca de base... los ids se saltan algunos numeros
# faltan <- data.frame(movie_id=c(1:3952)[!c(1:3952) %in% movies.df$movie_id], movie_nom=NA, tipo=NA)
# movies.df <- rbind(movies.df, faltan)
movies.df.2 <- na.omit(dplyr::right_join(unique(dat.2[,c("movie_id","movie_id_2")]),movies.df, by="movie_id"))


xx <- data.frame(movies.df.2 %>% arrange(movie_id_2), Q)


arrange(xx, desc(X1)) %>% head(20)
arrange(xx, desc(X1)) %>% tail(20)
arrange(xx, desc(X2)) %>% head(20)
arrange(xx, desc(X2)) %>% tail(20)
```


# Recomendaciones al usuario

Explica cómo hacer predicciones a partir del modelo (predicción de la calificación 1-5). ¿Qué películas recomendarías para el usuario usuario 4000 y el usuario 6000, y usuario 1333? (que no haya visto!)

```{r}
# Necesitamos las medias por pelicula
peli.media <- dat.entrena.2 %>% group_by(movie_id_2) %>% dplyr::summarise(media.peli = mean(rating)) %>% left_join(movies.df.2)
usuario.media <- dat.entrena %>% group_by(user_id) %>% summarise(media.usu = mean(rating))
media.gral <- mean(dat.entrena$rating)
usuario <- 4000

recomendar <- function(usuario){
# Extraemos las calificaciones que dio el usuario 1
califs.1 <- dat.entrena.2 %>% dplyr::filter(user_id==usuario) %>%
  arrange(desc(rating.adj))
#head(califs.1)

# Extraemos las predicciones de todas las peliculas para el usuario 4000
pred.1 <- data.frame(peli.media %>% arrange(movie_id_2), pred.x =  Q%*%P[usuario, ] ) %>%
    arrange(desc(pred.x)) %>%
    mutate(media.gral=media.gral,media.usuario=filter(usuario.media, user_id==usuario)$media.usu,
           rating.pred=pred.x + media.peli + media.usuario - media.gral) #calculamos las calis del 1-5 para todas las pelis para el usuario 4000
#head(pred.1,20)
# Necestiamos saber cuales peliculas ya vio para filtrarlas
ya_vio <- dat.2 %>% dplyr::filter(user_id==usuario) %>% dplyr::select(movie_id) %>% unique()

anti_join(pred.1,ya_vio) %>% arrange(desc(pred.x)) 
}

pred.1.1 <-recomendar(4000)
pred.1.1 %>% dplyr::select(movie_nom, tipo, rating.pred) %>% head(20)

```

Le recomendariamos las peliculas que mejor se ajustan al ususario (es decir, las mejores segun la prediccion de descenso en gradiente). Para recuperar el valor en la escala 1-5 debemos calcular $x_{ij}=r_{ij}+\hat{b_j} + \hat{a_i} - \hat{\mu}$.


Recomendaciones para el usuario 6000
```{r}
pred.2 <- recomendar(6000)
pred.2 %>% dplyr::select(movie_nom, tipo, rating.pred) %>% head(20)

```


Recomendaciones para el usuario 1333
```{r}
pred.3 <- recomendar(1333)
pred.3 %>% dplyr::select(movie_nom, tipo, rating.pred) %>% head(20)
```

# Evaluacion del modelo con validacion

Veamos como se ve el conjunto de validacion

```{r}
ggplot(dat.valida.2, aes(x=prediccion, y=rating, colour=factor(rating))) + geom_jitter()

# res=rating.adj
# calif=rating
# pred_base = prediccion

dat.valida.2$ajuste <- apply(dat.valida.2, 1, function(reng){ 
    Q[as.numeric(reng['user_id'])] * P[as.numeric(reng['movie_id_2'])]  
    }) 
dat.valida.2$pred <- dat.valida.2$ajuste + dat.valida.2$prediccion

ggplot(dat.valida.2, aes(x=rating.adj, y=ajuste, colour=factor(rating))) + geom_point()
```

Se observan algunas fallas pero en general el modelo mantiene a las personas en el lado correcto segun sus gustos. 


